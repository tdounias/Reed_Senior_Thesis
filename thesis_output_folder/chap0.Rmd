<!-- The {.unnumbered} option here means that the introduction will be "Chapter 0." -->

# Introduction {.unnumbered}

The democratic system is based on procedures as much as principles. The way that democracies chose to tally the will of the people is always a messy, controversial process. Thus the design and implementation of voting systems is far from being neutral; the decisions made on who votes, and how, when, and where they do so is inherently coupled with the outcome. Underlying those decisions is a nebulous, inconclusively answered question: are elections fair, and how can we make them more so.
	
The passage of the Help America Vote Act—or HAVA--[@robert_nay_help_2002], which mandated states to update and consolidate public voter registration files, and created the US Elections Assistance Commission that makes available county level data, innovated the way we use data based approaches to answer this question. HAVA offered political scientists and statisticians direct access to the voting population’s voting patterns, political registration, age, geolocation and much more; information that up to then was only accessible by sampling through surveys. The immense leap here happens because true population data does away with the need for sampling techniques that are often biased and inaccurate. This process was first used by private consulting firms that cleaned up the--on occassion rather messy--voter files, and used the data for private enterprise. Voting related theories derived from political science are now commonly tested using advanced statistical methods and huge amounts of data; both disciplines tackle these data to face joint problems such as quantifying the quality of voter registration files [@ansolabehere_quality_2010], or linking disparate voter records [@ansolabehere_adgn:_2017].