---
output: pdf_document
header-includes:
- \usepackage{graphicx,latexsym}
- \usepackage{amssymb,amsthm,amsmath}
- \usepackage{longtable,booktabs,setspace}
---

```{r setup, include = FALSE}
library(tidyverse)
library(lubridate)
library(Matrix)
library(lme4)
library(gamm4)
source("~/Desktop/Reed_Senior_Thesis/riggd/R/utils.R")
setwd("~/Desktop/Reed_Senior_Thesis/Data_and_results/data")

#DATA
load("all_turnouts.RData")
demographics <- read_csv("colorado_demographic_stats_by_county.csv")
names(demographics) <- tolower(names(demographics))

model_dt <- turnouts_county_data(turnout_list)

model_dt$dates <- as.factor(model_dt$dates)
model_dt$types <- as.factor(model_dt$types)

model_dt <- filter(model_dt, !is.na(model_dt$reg))

model_dt <- left_join(model_dt, demographics, by = "county")

model_dt$county <- as.factor(model_dt$county)

#Individual Model Data
model_sample <- read_csv("model_indiv_sample.csv")
```


# Model Specification and Results

In this chapter I do a step-by-step construction and fitting of a series of models. I begin with a thorough analysis of my notation, and specification of models. I then extract results from the models that best fit the data, and draw inferences on my hypotheses. I will start with a disclaimer: why the data available to me is not necessarily enough to get the necessary causal leverage for significant results. This is particularly true of individual level models. This disclaimer should be considered a large part of the analytical results of my thesis; given several months of exploratory data analysis, such explanations should serve future research into Colorado voter files. I will then proceed to construct some actual models--disclaimer notwithstanding--starting with county and proceeding to individual level modelling. Some of these models may be speculative, as given the initial disclaimer they require more data, or more processing power to actually run. I will still include them as they may be used for future research.

##Salt

The following models should be taken with a grain of salt because of a series of reasons. In this section, I will tackle these reasons one by one and then analyze what steps could be made to compensate.

### Causal Leverage

Causal leverage usually means having enough data to draw significant conclusions about correlation of variables, or in the best cases make safe causal inferences. Data that presents causal leverage should have certain characteristics. It should, first, be extensive enough. By this I mean that the raw number of observations should be as high as possible, and in the best cases significantly larger than the set of predictors that are present. This not only guarantees no issues with model matrices when running statistical models, but also that there will be enough data-per-variable to draw conclusions. Second, the data should be varied. To put it very simply, it's not enough to have hundreds of thousands of observations if they are all similar to eachother. If, for example, my data included a thousand people in Jefferson county, and 63 in all other counties of Colorado combined--one in each remaining county--, then I would not be able to leverage my data to draw conclusions on county-level effects. 

As previously stated, I have registration files going back to 2012. From these files, I have extracted data for elections going back to 2010 ^[See section 3.3.1; I extracted data limited to this time period to avoid accuracy issues with migration and removal of inactive/unavailable voters]. In order to make inferences on VBM and turnout effects, given the previous criteria for causal leverage, I had to have extensive and varied data. I have extensive data--over 35 million observations at the individual level--but the data substantially lacks variance in voting method. Put simply, most people in Colorado from 2010 onward either did not vote at all, or voted by mail. If you recall the changes in Colorado election law, in 2008 counties were allowed to conduct all mail elections, and no-excuse permanent absentee voting was implemented state-wide; then in 2013 Colorado transitioned to full VBM for all elections. This means that few people were still using traditional polling places or vote centers to cast their ballots. Figure 4.1 shows how, after 2013, and even before that in 2011--the coordinated, local election for which mail ballots were more convenient for counties--over 95% of ballots cast were mail ballots. Only in the general elections of 2010 and 2012 there is some variance, but mail ballots account for well over two thirds of total votes.

```{r vbm png, echo=FALSE, fig.cap="Percentage of mail ballots over total ballots by year", out.width = '60%', fig.align='center'}
knitr::include_graphics("/Users/tdounias/Desktop/Reed_Senior_Thesis/plots/vbm_county_graph.png")
```

This issue is not completely fatal for my county level models. There is still variance between counties that have 100% mail ballots and those that are around the 75-85% margin. For individual level models--where I am estimating voting probability--VBM will be an almost perfect predictor for voting, and therefore will not present me with any substantial analytical result on how it affects voting probability. There are some ways to compensate for this issue, which I outline; due to time or data constraints, not all of these will be implemented in this thesis:

* *More (Diverse) Data*: 

* *Localized, Natural Experiment Studies*: 

* *Synthetic Control Group*: 

### Lack of Individual Data

### Processing Power

## Models

### Variable Specification

I will not go through each individual variable in this section, but will briefly describe my procedure on notation for the following models. I will include more comments whenever they seem necessary under each model. In this thesis I include predictors on a series of variables that can be divided into five categories based on unit of observation: county, election, individual, local result, and ballot. The last two are functions of other units: local result units are equal to the product of elections and counties, while ballot units are equal to the number of unique individuals multiplied by the number of elections each of them was registered in. For notation, I follow this set of rules:  
  
1. If the variable is a response, it is coded $y$.
2. If the variable is a predictor, it is coded according to Table 4.1. 
3. The variable's superscript will provide information on what it represents, else it will be explained.
4. All variables represent a single value of that variable unless stated otherwise.
5. Unit of observation will also be specified in subscript, according to the indices described in Table 4.1. These indices are also used in sum notation.
6. All Greek characters represent coefficients to be calculated.
7. By $k[j]$ I represent the k-value of the j-observation. In this case, this would be the county that an individual is registered in.
8. Note that for Local Result level variables, I use $k,l$ as an indice. This is because there are very few variables at this level, it is a direct multiplicative product of two other units, and this notation avoids confusion with even more indice types.

------------------------------------------------
  Units                  Variable       Index 
-------------------- --------------- ----------- 
  Ballot                     u            i
  
  Individual                 z            j
  
  County                     x            k
  
  Election                   w            l  
  
  Local Result               v            k,l
  
  General Index              -            i'
-------------------- --------------- -----------
Table: Variable names and indices per unit of observation \label{tab:units_vars}

## County Level Models

### Specifications

In this section I will go through a step-by step creation of models at the county level. County level models use a series of variables at the election, county, and local result levels. The response variable is always turnout as a local result. If this model is considered at its most basic, it could be thought of as an assignment of voting tendencies across counties; each county independent of election has a unique range of turnout results. In this way it is possible to build a naive, baseline model of turnout as follows:

$$y^{turnout}_{k,l} = \beta_0 + (\sum_{k=1}^{64}\beta_kx_k^{county}),$$

where $x_k^{county}$ is a series of 64 dummy variables for each county of Colorado. Here differences between elections come from normally distributed error terms, rather than predictors. I name this *Model 1*, and it does not reflect the data particularly well. First off, this model includes the assumption that counties are independent of one another, which is probably false; just consider that these counties are areas of the same state, in the same country, with populations moving between them at regular intervals, and many of them covering the same metropolitan area or congressional district. Additionally, this model cannot fully calculate relevant coefficients, since a number of counties can be represented as perfect linear functions of the other variables. This means they will be dropped by \textit{R} when the model is called in the `lm()` function.  
  
A way to fix both these issues is to use a multilevel model with mixed effects for county. By constraining coefficients at the county level to a set distribution, this model does away with the assumption of independence. The other county level predictors help to explain some of the unexplained group level variation, which reduces the standard deviation of county coefficients and helps provide more exact estimates [@gelman_data_2006]. I call this *Model 2*, which can be written as:

$$y^{turnout}_{k,l} = a_{k} + \beta_{1}x_k^{\%white} + \beta_{2}x_k^{\%urban},$$

$$a_{k} \sim N (\gamma_0, \sigma_{\alpha}^2)$$
   
This model provides a more reasonable set of estimates for each county, but still fails at providing any sort of guess as to secular trends, time-specific effects, election type effects, or mail voting--the variable of interest. I will amend this by adding a set of variables at the election and local result levels: election type and an interaction term between election type and mail voting. This variable should reflect whether turnout effects of mail voting are more pronounced in a specific type of election. I call this *Model 3* and it can be specified as follows:

$$y^{turnout}_{k,l} = a_{k} + \beta_{1}x_k^{\% white} + \beta_{2}x_k^{\% urban} + (\sum_{i'=1}^{4}\beta_{i'+3}w_{i'}^{election type})*(\beta_3v_{k,l}^{\% mail~vote} + 1),$$

$$a_{k} \sim N(\gamma_0, \sigma_{\alpha}^2)$$

where $w_{i'}^{election type}$ is a series of four dummy variables for each type of election (General, Primary, Coordinated, Midterm). This model reflects nearly all the information I have available, apart from election date. For the incorporation of election dates there are two possible alternatives. First, I can simply add a dummy variable for each year. This would assume independence between each year, as it would specify different, independent "slopes" for the seven years I have data for--this is like calculating seven different models, one for each year. This is not particularly elegant as a solution nor does it reflect the fact that years actually are interconnected; of course there can be massive shifts in national or regional political climates, but those shifts happened _from some baseline_, which is reflected in previous years.   
  
These elections can be thought of as systems for which prior condition affects future outcomes, and therefore time cannot be modeled as a series of independent effects. The solution here is adding a spline function for time, using a general additive multilevel model. The most commonly used spline function, and the default in the `gamm4` \textit{R} package is a thin plate regression spline, which I also use here [@wood_generalized_2006]. More on the subject of splines can be found in the Wood (2006) textbook. The model, which I call *Model 4* can be written as follows:  
  
$$y^{turnout}_{k,l} = a_{k} + \beta_{1}x_k^{\% white} + \beta_{2}x_k^{\% urban} + (\sum_{i'=1}^{4}\beta_{i'+3}w_{i'}^{election type})*(\beta_3v_{k,l}^{\% mail vote} + 1) + s(w^{year}_{l}),$$

$$a_{k} \sim N(\gamma_0, \sigma_{\alpha}^2)$$
where $s()$ is a thin plate spline function with seven knots--equal to the number of years.^[I used the `gam.check()` function that is present in the `mgcv` \textit{R} package, whose call determined that the number of knots here may be too low. However, given the data available to me, I was limited to the inclusion of seven years and as such cannot increase the number of knots any further.] A summary of these four models is provided in the following table:  
  
-------------------------------------------------------------------------------------------------
  Model No                                    Model Description
-------------- ----------------------------------------------------------------------------------
  Model 1          Naive model with only county specific effects
  
  Model 2          Multilevel model; added county level predictors
  
  Model 3          Multilevel model; added VBM, interaction terms, and election fixed effects
  
  Model 4          Multilevel General Additive model; added spline function for election year
-------------- ----------------------------------------------------------------------------------
Table: County level model descriptions \label{tab:model_desc_county}

### Results

The table in this section presents coefficients and standard errors for all four county level models. This table does not include any metrics for county--either mixed or fixed effects. I have chosen to omit these because they firstly are not very relevant to my hypotheses, and secondly because they are very extensive--64 coefficients for each of the four models. I have also not included any metric for time--here measured in years and used only in the fourth model. Both the mixed effects for county and the measure for time should be considered as controls: the first controls for county-specific trends while still restricting these to allow for non-independence, and the second makes sure that my results are indicative of a secular trend, independent of any shifts along time.  

-------------------------------------------------------------
      Variables        Model 1   Model 2   Model 3   Model 4 
--------------------- --------- --------- --------- ---------
      Intercept         0.369     0.492     0.455     0.470  

                       (0.60)    (0.045)   (0.078)   (0.072) 

      Pct_white                   0.034     0.033     0.031  

                                 (0.053)   (0.050)   (0.050) 

      Pct_urban                  -0.118    -0.117    -0.119  

                                 (0.022)   (0.021)    (0.021) 

     typeGeneral                            0.190     0.254  

                                           (0.070)   (0.065) 

     typeMidterm                            0.252     0.070  

                                           (0.068)    (0.063) 

     typePrimary                           -0.071    -0.170  

                                           (0.069)   (0.062) 

 typeCoordinated*VBM                       -0.001     0.002  

                                           (0.067)   (0.058) 

   typeGeneral*VBM                          0.151     0.087  

                                           (0.033)   (0.037) 

   typeMidterm*VBM                         -0.058     0.109  

                                           (0.026)   (0.030) 

   typePrimary*VBM                         -0.089    -0.003  

                                           (0.028)   (0.027) 
-------------------------------------------------------------
Table: Estimated coefficients for County level models \label{tab:model_county_coefs}
  
Given that, the first observable result is that the percentage of white population and the percentage of urban population are fairly stable indicators of a small positive and negative shift in turnout respectively. The lack of variability between models is not surprising; these represent a county-level, time-independent demographic statistic, and there would be no reason to assume that part of their effect would be subsumed by other variables in models 3 and 4.  
  
Moving on to election type, the first thing to note is that there is no typeCoordinated in the table. This is because of the way \textit{R} displays and calculates models for discrete variables, when they are coded as indicators. The coefficients for the different election types should be read as differences from the "baseline" that is typeCoordinated. First surprising result here is that the coefficient for general presidential elections is substantially lower than that of midterms. Or rather this would be surprising if we did not notice the interaction terms with VBM, which indicate that, after allowing for VBM effects, presidential elections do actually have higher turnout in my model than midterms do. Other than this, coefficients in model 3 and model 4 *individualy* make sense, in the assumed ordering of turnout in such elections--presidential, then midterm, then coordinated and lastly primary.   

Next, taking election type and all interaction terms into consideration, let's examine what happens when the spline function for time is introduced between models 3 and 4. Most coefficients shift dramatically, with the exception of the interaction between coordinated elections and VBM. This dramatic shift--between 5 and 15(!) percentage points--indicates that several of the effects that the third model estimated are actually time-specific trends, and that there is a significant difference if we account for them. In the fourth model, the coefficients for election type on their own are still indicative of a common assumption on turnout in such elections^[Also see Figure 3.4]. As for interaction terms with VBM, the effect of VBM on primary election turnout is almost wiped out entirely, the interaction with general election turnout is depleted but still present at around 8%, and coordinated election VBM effects remain virtually non-existent. Interestingly, the effect of VBM on midterm turnout switches sign from a negative effect of 5% to a positive effect of around 11%; making midterm elections the most heavily affected by mail voting.  
  
Taking my hypotheses one by one, these models present evidence less in favor of H1, than against its alternate, H1'. While mail voting does seem to affect turnout in a way consistent across time--see the coefficients for VBM effects on general and midterm elections--this effect is not particularly more strong than the percentage of urban population in each county. This result is ambiguous, and therefore does not present concrete evidence as to the validity of H1. Conversly, if going off of these models my second and third hypotheses can be convincingly rejected. After controlling for time, the effect that VBM has on coordinated or primary elections is marginal at best, compared to more consistent effects on midterm and general elections. The one point in favor of H3 here is that the effect of VBM on midterm elections is slightly higher--about 2%--than the effect on presidential elections in model 4. However, this difference is not significant enough to rule in favor of H3; if this difference was caused by the lack of presence of national effects, it would be significantly more pronounced in primary and coordinated elections. As such, I would ascribe this difference to some omited variable, or other effect that I do not include in my models.


## Individual Level Models

### Specifications
  
For the rest of this section, assume the following:

$$y_i \sim \text{Bernoulli}(p\_vote)$$  

Where $y_i \in \{0,1\}$ is the probability that the i-th ballot was completed.   
  
In this section I do not linearly add to the model until it reaches a final stage. The reasoning here is that there is no exact linear path to follow; there is an overarching unit of observation--the ballot--and all the rest are dependent between each other. For instance, adding a variable for Party at the ballot level would not significantly change the way I later add percentage of white residents at the county level. Therefore, the way I proceed is the following: I "build" the models step by step and separately for each group of variables (grouping by unit of observation). Then I present one example of what a model using two of these initial "building blocks" would look like. Since this is fairly generalizable, I then proceed directly to the full model which includes all different variables. Some models will be named; the models for which I do so are the ones for which an \textit{R} call is attempted, and results in either estimation of coefficients or some interesting observation on why their call was not possible. 
   
If receiving a ballot with no information, I would predict that the probability that an additional ballot was a vote in favor would be equal to turnout, as calculated through all other ballots. Therefore:

$$\hat{p\_vote}_i = \frac{\# \text{votes cast}}{\# \text{ballots}}$$
  
### Estimation with only one type of data
   
There are four levels of data I will go through here: County, Election, Person, and Ballot. 
  
#### County Level
  
Assume that the ballot I am trying to assess completion for has the name of the county it is from written on it. There are two ways I can think of for predicting $p\_vote$. First, assume that each different county has a different, independent $p\_vote$. Therefore, in model-lingo this would look like:

$$\hat{p\_vote}_i \sim \text{logit}^{-1}(\sum_{k = 1}^{64}x_{k,i}\beta_{k})$$

Where k counts over the 64 counties of Colorado, and $x_{k}$ is an indicator variable for each county. If I, quite reasonably, throw away the assumption of independence--these counties are, after all, in the same state and the same country--I could also fit a mixed effects model as such:
  
$$\hat{p\_vote} \sim \text{logit}^{-1}(a_{k[i]}), $$
$$a_{k} \sim \text{N}(\gamma_0, \sigma_{\alpha}^2)$$
  
Where $\alpha_{k[i]}$ varies by county, constrained by its standard deviation and $\gamma_0$, an intercept coefficient. I name this *Model 1*.
```{r indiv model 1}
#Run the model
md_1 <- glmer(family = "binomial", data = model_sample, 
              voted ~ (1|COUNTY))

#Display results
arm::display(md_1)

#Fixed effects
fixef(md_1)
```

Let's say now that along with the one ballot, I was given a short list of $n^{\text{county vars}}$ other county-level variables, be they discrete, continuous, or indicators. The two models would then look like:  

$$\hat{p\_vote}_i \sim \text{logit}^{-1}(\sum_{k = 1}^{64}x_{k}\beta_{k} + \sum_{i'=1}^{n^{\text{county vars}}}x_{k[i], i'}\beta_{i'+64})$$
   
Where $x_{k[i], l}$ is the k-th value of the i'-th variable. If, as before, I do not assume independence, the model can be written as:
  
$$\hat{p\_vote} \sim \text{logit}^{-1}(a_{k[i]}), $$
$$a_{k} \sim \text{N}(\gamma_0 + \sum_{i'=1}^{n^{\text{county vars}}}x_{k[i], i'}\gamma_{i'}, \sigma_{\alpha}^2)$$
  
In the case of my specific data, for the time being I have county-level data for white population and urban population, so $n^{\text{county vars}} = 2$. I name this *Model 2*

```{r indiv model 2}
#Run the model
md_2 <- glmer(family = "binomial", data = model_sample, 
              voted ~ (1|COUNTY) + PCT_URBAN + PCT_WHITE)

#Display results
arm::display(md_2)

#Fixed effects
fixef(md_2)
```

   
#### Individual Level
   
Assuming that I know the voter ID of the individual that cast their ballot, I can treat this piece of information in about the same way that I did for county as described above. This means that the following is mostly an exercise in maintaining notation constant. For these purposes, let $n^{ID}$ be the number of total unique voter IDs--individuals--that I have data on, and j an indice that sums over all individuals. Also let $z_{j}$ be an indicator variable for each individual. Then:
 
$$\hat{p\_vote}_i \sim \text{logit}^{-1}(\sum_{j = 1}^{n^{ID}}z_{j}\beta_{j})$$

And the second model, not assuming independence, would be: 

$$\hat{p\_vote} \sim \text{logit}^{-1}(\delta_{j[i]}), $$
$$\delta_{j} \sim \text{N}(\zeta_0, \sigma_{\delta}^2)$$

Again, in a similar way to county level data, there are variables at an individual level, thus making it relatively easy to build further models. Let's say now that along with the one ballot, I was given a short list of $n^{\text{indiv vars}}$ other individual-level variables, be they discrete, continuous, or indicators. The two models would then look like:

$$\hat{p\_vote}_i \sim \text{logit}^{-1}(\sum_{j = 1}^{n^{ID}}z_{j}\beta_{j} + \sum_{i'=1}^{n^{\text{indiv vars}}}z_{j[i], i'}\beta_{i'+n^{ID}})$$
   
Where $z_{j[i], l}$ is the j-th value of the i'-th variable. If, as before, I do not assume independence, the model can be written as:

$$\hat{p\_vote} \sim \text{logit}^{-1}(\delta_{j[i]}), $$
$$\delta_{j} \sim \text{N}(\zeta_0 + \sum_{i'=1}^{n^{\text{indiv vars}}}z_{j[i], i'}\delta_{i'}, \sigma_{\delta}^2)$$
  
In the case of my specific data, for the time being I have individual-level data for gender, so $n^{\text{indiv vars}} = 1$. I name this model *Model 3*.
   
#### Election Level
   
Again as previously, four models come from including election level data. The first two are assuming I only knew what specific election the ballot comes from. Let $w_{i'}$ be an indicator variable for each election and $n^{elect}$ the number of elections. The model assuming independence, with $w_{i'}$ being indicator variables for each election, is:

$$\hat{p\_vote}_i \sim \text{logit}^{-1}(\sum_{l = 1}^{n^{elect}}w_{l}\beta_{l})$$

Again, as previously, it would be safe to assume that each election is not held in a vacuum. Adding mixed effects this model would be:

$$\hat{p\_vote} \sim \text{logit}^{-1}(\eta_{l[i]}), $$
$$\eta_{l} \sim \text{N}(\nu_0, \sigma_{\nu}^2)$$

Again, in a similar way to county and individual level data, I add in variables at an election level. Let's say now that along with the one ballot, I was given a short list of $n^{\text{election vars}}$ other election-level variables, be they discrete, continuous, or indicators. The two models would then look like:

$$\hat{p\_vote}_i \sim \text{logit}^{-1}(\sum_{l = 1}^{n^{elect}}w_{l}\beta_{l} + \sum_{i'=1}^{n^{\text{election vars}}}w_{l[i], i'}\beta_{i'+n^{elect}})$$
Where $w_{l[i], i'}$ is the l-th value of the i'-th variable.

Assuming independence:
$$\hat{p\_vote} \sim \text{logit}^{-1}(\eta_{l[i]}), $$
$$\eta_{l} \sim \text{N}(\nu_0 + \sum_{i'=1}^{n^{\text{election vars}}}w_{l[i], i'}\nu_{i'}, \sigma_{\nu}^2)$$
For the time being I have two different variables that describe individual elections: date and type. Note that the above models may not be the best way to describe dates! An alternative could be fitting a glm, with some smoothing spline function for year. As for type, this would include four distinct indicators; one for each election type. I name this final model--including a smoothing spline for year, *Model 4*. Model 4 would not be a mixed effects model, since all the variability between elections is incorporated in election type and election year--with those two variables I can fully describe each election.

#### Ballot Level
   
In this section I assume that the ballot has some key features written on it, like the voting method, age, or party registration of the person that filled it out. A mixed effects model here would make no sense, since all the data is at the same unit of observation. Therefore, when adding ballot level variables, the model would look like:

$$\hat{p\_vote}_i \sim \text{logit}^{-1}(\beta_0 + \sum_{i' = 1}^{n^{\text{ballot vars}}}u_{i,i'}\beta_{l'})$$

Where $u_{i,i'}$ is the i-th value of the i'-th variable, and $n^{\text{ballot vars}}$ is the number of ballot level variables. For now, I have data on voting method, age, and party. Voting method is coded as a binary variable with value one if the method was a Mail Vote. Party includes four distinct indicators for REP, DEM, Other, and Unaffiliated. Age is tricky; for now the options would be: inclusion as an integer, inclusion as a cubic polynomial, inclusion as a 2nd degree polynomial, inclusion in some form of spline function. 
   
### Estimation with two types of data

After the work of setting up the four models at four different levels of observation, combining them in twos should be fairly straightforward. To avoid being needlessly cumulative, I will pursue this combination for County and Individual level only--instead of the six different possible combinations.

With the assumption that both counties and individuals are independent of one another, I proceed to the first type of model:

$$\hat{p\_vote}_i \sim \text{logit}^{-1}(\sum_{k = 1}^{64}x_{k}\beta_{k} + \sum_{i'=1}^{n^{\text{county vars}}}x_{k[i], i'}\beta_{i'+64} + \sum_{j = 1}^{n^{ID}}z_{j}\beta_{j + n^{\text{county vars}} + 64} + \sum_{i'=1}^{n^{\text{indiv vars}}}z_{j[i], i'}\beta_{i'+n^{ID} + n^{\text{county vars}} + 64})$$

This is large and clunky. It includes variables as described above: indicators for each county and individual, and all individual or county-level variables. For the corresponding mixed-effects model, I assume the tree-like structure we discussed on Monday. The hierarchy has two "levels", with the second level consisting of two different regressions; this will be *Model 5*


$$\hat{p\_vote} \sim \text{logit}^{-1}(\delta_{j[i]} + a_{k[i]}), $$
$$a_{k} \sim \text{N}(\gamma_0 + \sum_{i'=1}^{n^{\text{county vars}}}x_{k[i], i'}\gamma_{i'}, \sigma_{\alpha}^2)$$
$$\delta_{j} \sim \text{N}(\zeta_0 + \sum_{i'=1}^{n^{\text{indiv vars}}}z_{j[i], i'}\delta_{i'}, \sigma_{\delta}^2)$$

### Estimation with the full dataset

I now proceed to include variables from all units of observation into one model. The first model, assuming independence, is:

$$
\begin{aligned}
\hat{p\_vote}_i \sim \text{logit}^{-1}(\sum_{k = 1}^{64}x_{k}\beta_{*} + \sum_{i'=1}^{n^{\text{county vars}}}x_{k[i], i'}\beta_{*} + \sum_{j = 1}^{n^{ID}}z_{j}\beta_{*} + \sum_{i'=1}^{n^{\text{indiv vars}}}z_{j[i], i'}\beta_{*} + \\
\sum_{l = 1}^{n^{elect}}w_{l}\beta_{*} + \sum_{i'=1}^{n^{\text{election vars}}}w_{l[i], i'}\beta_{*} + \sum_{i' = 1}^{n^{\text{ballot vars}}}u_{i,i'}\beta_{*})
\end{aligned}
$$

You will notice that I have omitted the subscript for all beta coefficients. This is because after two or three parameters, this becomes very, very large. I think it's reasonable to assume increasing indexes for different beta coefficients from left to right in this expression.

The mixed effects model will again operate on two "levels" of hierarchy, but the second level will now include three distinct regressions. Caveats for variables like age and date should be noted from previous sections. This, the most complete model, will be *Model 6*

$$\hat{p\_vote} \sim \text{logit}^{-1}(\sum_{i' = 1}^{n^{\text{ballot vars}}}u_{i,i'}\beta_{l'} +\delta_{j[i]} + a_{k[i]} + \eta_{l[i]}),$$

$$a_{k} \sim \text{N}(\gamma_0 + \sum_{i'=1}^{n^{\text{county vars}}}x_{k[i], i'}\gamma_{i'}, \sigma_{\alpha}^2)$$

$$\delta_{j} \sim \text{N}(\zeta_0 + \sum_{i'=1}^{n^{\text{indiv vars}}}z_{j[i], i'}\delta_{i'}, \sigma_{\delta}^2)$$

$$\eta_{l} \sim \text{N}(\nu_0 + \sum_{i'=1}^{n^{\text{election vars}}}w_{l[i], i'}\nu_{i'}, \sigma_{\nu}^2)$$

In summary, Table 4.3 includes all noteworthy models from the previous section. I add a few models which should be easily understood based on the specifications given above.  

-------------------------------------------------------------------------------------------------
  Model No                                    Model Description
-------------- ----------------------------------------------------------------------------------
  Model 1          Naive model with only county mixed effects
  
  Model 2          Multilevel model; added county level predictors
  
  Model 3          Multilevel model; individual-level mixed effects and predictors
  
  Model 3a         A combination of 2 and 3 without individual-level mixed effects
  
  Model 4          General Additive model; election predictors and time smoothing splines
  
  Model 5          Multilevel General Additive model; election, individual, county mixed effects and all predictors
-------------- ----------------------------------------------------------------------------------
Table: Individual level model descriptions \label{tab:model_desc_individual}
